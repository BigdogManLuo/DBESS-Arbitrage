# Economic Operation Strategy of Distributed Battery Energy Storage System
## Background
The distributed energy storage system has controllable charging and discharging power. When connected to the grid, energy storage operators can
High-fat strategy for profit. Under the needs of individual autonomous optimization of energy storage and centralized control and modeling of energy storage
Under the limitation of high cost and large amount of calculation, we can propose a new method based on the law and periodicity of real-time electricity
The model-free energy storage self-optimization management and control strategy allows distributed energy storage to adapt to the real-time electricity price environment.
The environment interaction training realizes the optimal policy.
## My Work
In this project, we can establish a mathematical model with the goal of maximizing long-term cumulative income of energy storage operators. The model takes into account the constraints of energy storage's charging and discharging power, capacity, operating cost, and aging cost.
and state transition equation, and write the Q-learning algorithm in reinforcement learning to realize the self-optimizing operation of energy storage.
In the real-time electricity price example test, the energy storage devices trained through reinforcement learning can reflect the real-time electricity price under the real-time electricity price.
Reflect the law of low storage and high development. In the calculation example test comparing the performance of intelligent algorithms such as simulated annealing and genetic algorithm,
Reinforcement learning methods have obvious advantages in achieving maximum cumulative gain and generalization ability. due to electricity
The price data reflects the volatility of the load and has a 24-hour period. Through the pre-training of historical data, the storage
The energy equipment can form a better state action value function, and when new data arrives, only a small number of times are required.
Training without re-doing a lot of computations like smart algorithms do. Since Q-learning only works with states
When space (energy storage power and time) and action space (charging and discharging power) are discrete, discrete
It cannot be adapted to large-scale energy storage systems. Further consideration is given to using deep reinforcement learning such as DQN.
algorithm is optimized. <br>
See documentation for details

## File Description
Real-time scripting using MATLAB
### src folder
calcuC.m: Calculate the DBESS aging cost function <br>
updateS.m: SOC state transition equation of DBESS <br>
case1-case5.mlx: The source file of each case, the mlx file can only be opened with matlab <br>
draw1-draw5.mlx: visualization of each example <br>
### data folder
The data file is the data needed for the visualization of the example, which is generated by case1~5 <br>
### pictures folder
The picture file is the running result of the visualization of the example
### Visual Instructions
When running the visual live script (draw1~draw5), please pay attention to the following points:<br>
<br>
1. Please make sure to run the case script corresponding to the case before running the draw script
2. Make sure the data file is imported into the working folder of matlab
